{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 10 (2532313086.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    messages = [{\"role\": \"user\", \"content\": f'!!!Напиши только Yes/No!!! скажи есть ли решение этого вопроса {\"Какие требования к программному обеспечению для работы с порталом?\"} в этой статье {data[el]} '}]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 10\n"
     ]
    }
   ],
   "source": [
    "    # Генерируем ответ на основе сообщений\n",
    "# Используем pipeline как высокоуровневый помощник\n",
    "from transformers import pipeline\n",
    "\n",
    "# Используем модель Phi-3-mini-4k-instruct\n",
    "pipe = pipeline(\"text-generation\", model=\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)\n",
    "\n",
    "import json\n",
    "data = json.load(open('data.json', 'r', encoding='utf-8'))\n",
    "for el in data:\n",
    "    messages = [{\"role\": \"user\", \"content\": f'!!!Напиши только Yes/No!!! скажи есть ли решение этого вопроса {\"Какие требования к программному обеспечению для работы с порталом?\"} в этой статье {data[el]} '}]\n",
    "    response = pipe(messages, max_new_tokens=512, do_sample=True, temperature=0.7, use_cache=False)\n",
    "    print(el, response[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('docs/dataset.parquet')\n",
    "data = dict()\n",
    "for i in range(len(df)):\n",
    "    data[i] = [df.iloc[i]['Заголовок статьи'], df.iloc[i]['Описание']]\n",
    "\n",
    "import json\n",
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеку SymSpell для проверки орфографии\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Инициализируем SymSpell с правильными параметрами\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "# Загружаем словарь для русского языка\n",
    "# SymSpell использует словарь частотности слов для работы\n",
    "dictionary_path = \"dictionary_ru.txt\"\n",
    "\n",
    "# Загружаем словарь в SymSpell\n",
    "if not sym_spell.load_dictionary(dictionary_path, encoding='utf-8', term_index=0, count_index=1):\n",
    "    print(f\"Ошибка загрузки словаря из {dictionary_path}\")\n",
    "\n",
    "# Функция для проверки орфографии\n",
    "def check_spelling(word):\n",
    "    # Получаем предложения для исправления\n",
    "    suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "    \n",
    "    if suggestions:\n",
    "        return f\"Возможно, вы имели в виду: {suggestions[0].term} (расстояние: {suggestions[0].distance})\"\n",
    "    return \"Исправлений не найдено. Возможно, префикс слишком короткий или словарь не содержит подходящих слов.\"\n",
    "\n",
    "# Проверяем ввод пользователя\n",
    "user_input = \"звявка\"\n",
    "print(check_spelling(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL для получения списка всех документов\n",
    "url = \"http://localhost:7777/query\" \n",
    "\n",
    "# Параметры запроса\n",
    "params = {\n",
    "    \"query\": \"звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки звявки \"\n",
    "}\n",
    "\n",
    "# Выполняем GET-запрос\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Выводим ответ\n",
    "print(response.json())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "\n",
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['Привет! Как твои дела?',\n",
    "             'А правда, что 42 твое любимое число?']\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
